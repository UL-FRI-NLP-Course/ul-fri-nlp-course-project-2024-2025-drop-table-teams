{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f85c05e65c70bc0",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [boshko.koloski@ijs.si](mailto:boshko.koloski@ijs.si) for any comments.</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771ac5b7cccdd00",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The core functionality of this notebook is to create a retrieval-augmented generation (RAG) system that enables discussion about the NLP subject setting using the `Mistral-7b-v0.2` model.\n",
    "\n",
    "General-purpose language models can be fine-tuned for common tasks such as sentiment analysis and named entity recognition, which typically do not require additional background knowledge.\n",
    "\n",
    "For more complex and knowledge-intensive tasks, it is possible to construct a language model-based system that accesses external knowledge sources. This approach enhances factual consistency, improves the reliability of responses, and mitigates the issue of 'hallucination.'\n",
    "\n",
    "Researchers have introduced the Retrieval Augmented Generation (RAG) method to address these knowledge-intensive tasks. RAG integrates an information retrieval component with a text generator model, allowing for efficient updates and modifications to its internal knowledge without retraining the entire model.\n",
    "\n",
    "RAG operates by taking an input, retrieving a set of relevant or supporting documents from a source like Wikipedia, and concatenating these documents with the original input prompt. This concatenated context is then fed to the text generator, which produces the final output. This adaptability is crucial for situations where facts may evolve over time, as the static parametric knowledge of traditional large language models (LLMs) can become outdated. RAG circumvents the need for retraining, providing access to the most current information and enabling reliable outputs through retrieval-based generation.\n",
    "\n",
    "RAG requires additional document embeddings and the storage of documents in a database for retrieval purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023bf09e0d6f6d8",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Run the cells below to setup and install the required libraries. For our experiment we will need `bitsandbytes`, `accelerate`, `transformers`, `datasets`, `sentence-transformers` and  `faiss-gpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a96eb267c0a6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T14:49:46.263474Z",
     "start_time": "2025-04-22T14:49:08.080073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: accelerate in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: unstructured in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: python-docx in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (5.3.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (4.13.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (2.2.0)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (3.13.0)\n",
      "Requirement already satisfied: backoff in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (0.33.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.10.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: olefile in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (44.0.2)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (0.2.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (5.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain bitsandbytes accelerate sentence-transformers faiss-cpu langchain_community unstructured python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f8a8e3-3702-4be1-bd8d-35508fd01722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-win_amd64.whl (2449.4 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.10.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sigors\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.5.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cu121\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e3501f-3a53-4b33-a6ac-862d4a00b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "False\n",
      "12.1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(torch.cuda.is_available())           \u001B[38;5;66;03m# should be True\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(torch.version.cuda)                  \u001B[38;5;66;03m# should show 12.1\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_device_name\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m)       \u001B[38;5;66;03m# should return your GPU name\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:493\u001B[39m, in \u001B[36mget_device_name\u001B[39m\u001B[34m(device)\u001B[39m\n\u001B[32m    481\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_device_name\u001B[39m(device: Optional[_device_t] = \u001B[38;5;28;01mNone\u001B[39;00m) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    482\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Get the name of a device.\u001B[39;00m\n\u001B[32m    483\u001B[39m \n\u001B[32m    484\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    491\u001B[39m \u001B[33;03m        str: the name of the device\u001B[39;00m\n\u001B[32m    492\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m493\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_device_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m.name\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:523\u001B[39m, in \u001B[36mget_device_properties\u001B[39m\u001B[34m(device)\u001B[39m\n\u001B[32m    513\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_device_properties\u001B[39m(device: _device_t) -> _CudaDeviceProperties:\n\u001B[32m    514\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Get the properties of a device.\u001B[39;00m\n\u001B[32m    515\u001B[39m \n\u001B[32m    516\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    521\u001B[39m \u001B[33;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[32m    522\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m523\u001B[39m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[32m    524\u001B[39m     device = _get_device_index(device, optional=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    525\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m device < \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device >= device_count():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:319\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mCUDA_MODULE_LOADING\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m os.environ:\n\u001B[32m    318\u001B[39m     os.environ[\u001B[33m\"\u001B[39m\u001B[33mCUDA_MODULE_LOADING\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mLAZY\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_cuda_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001B[39;00m\n\u001B[32m    321\u001B[39m \u001B[38;5;66;03m# we need to just return without initializing in that case.\u001B[39;00m\n\u001B[32m    322\u001B[39m \u001B[38;5;66;03m# However, we must not let any *other* threads in!\u001B[39;00m\n\u001B[32m    323\u001B[39m _tls.is_initializing = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())           # should be True\n",
    "print(torch.version.cuda)                  # should show 12.1\n",
    "print(torch.cuda.get_device_name(0))       # should return your GPU name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ba74db4cddd67",
   "metadata": {},
   "source": [
    "**In simple terms, RAG is to LLMs what an open-book exam is to humans.**\n",
    "\n",
    "The concept of an open-book exam centers around assessing a student's reasoning abilities rather than their capacity to memorize specific details. In a similar vein, RAG separates factual knowledge from the LLM’s reasoning capabilities. This factual information is stored in an external knowledge source, which is both easily accessible and updatable:\n",
    "\n",
    "- **Parametric knowledge:** Knowledge that is learned during training and implicitly stored within the neural network's weights.\n",
    "- **Non-parametric knowledge:** Information that is stored externally, for example, in a vector database.\n",
    "e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700794adcf9e90c",
   "metadata": {},
   "source": [
    "![RAG](RAG.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354fcc51dcd38f7",
   "metadata": {},
   "source": [
    "The RAG workflow consists of:\n",
    "\n",
    "1. **The Retrieve**: The user query is used to retrieve relevant context from an external knowledge source. For this, the user query is embedded using an embedding model into the same vector space as the additional context in the vector database. This enables a similarity search, and the top k closest data objects from the vector database are returned.\n",
    "2. **Augment**: The user query and the retrieved additional context are incorporated into a prompt template.\n",
    "3. **Generate**: Finally, the retrieval-augmented prompt is fed to the LLM.\n",
    "\n",
    "We will use the `langchain` framework to efficiently prompt the LLMs and prepare the RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90ca0fc832d952b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T14:49:56.432393Z",
     "start_time": "2025-04-22T14:49:56.427435Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import requests\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d512e20afb17a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T14:49:57.628754Z",
     "start_time": "2025-04-22T14:49:57.623811Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown\n",
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, HTMLHeaderTextSplitter, TokenTextSplitter\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_community.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83fba5f29fed05c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:30:05.385698Z",
     "start_time": "2025-04-22T15:30:05.279154Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m LLM_MODEL = \u001B[33m\"\u001B[39m\u001B[33mmistralai/Mistral-7B-Instruct-v0.2\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m device = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mcuda:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:674\u001B[39m, in \u001B[36mcurrent_device\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    672\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcurrent_device\u001B[39m() -> \u001B[38;5;28mint\u001B[39m:\n\u001B[32m    673\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m674\u001B[39m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    675\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch._C._cuda_getDevice()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    235\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    236\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    237\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmultiprocessing, you must use the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mspawn\u001B[39m\u001B[33m'\u001B[39m\u001B[33m start method\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch._C, \u001B[33m'\u001B[39m\u001B[33m_cuda_getDeviceCount\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m239\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTorch not compiled with CUDA enabled\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[32m    242\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mAssertionError\u001B[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "LLM_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = f\"cuda:{torch.cuda.current_device()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b1984d75e78",
   "metadata": {},
   "source": [
    "Large Language Models are known for their significant computational demands. Typically, the size of a model is determined by multiplying the number of parameters (size) by the precision of these values (data type). To conserve memory, weights can be stored using lower-precision data types through a process known as quantization.\n",
    "\n",
    "**Post-Training Quantization (PTQ)** is a straightforward technique where the weights of an already trained model are converted to a lower precision without necessitating any retraining. Although easy to implement, PTQ can lead to potential performance degradation.We will employ PTQ using the `bitsandbytes` library and will load the model in 4-bit precision, applying double quantization with the `nf4` data type. For more information about quantization, visit [this guide on quantization](https://huggingface.co/docs/optimum/en/concept_guides/quantization) )pe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6330616774c702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T14:50:03.680029Z",
     "start_time": "2025-04-22T14:50:03.669881Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # loading in 4 bit\n",
    "    bnb_4bit_quant_type=\"nf4\", # quantization type\n",
    "    bnb_4bit_use_double_quant=True, # nested quantization\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b44c55df481fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:04:39.048894Z",
     "start_time": "2025-04-22T15:04:38.216612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `jupyter-notebook` has been saved to C:\\Users\\sIGORs\\.cache\\huggingface\\stored_tokens\n",
      "Your token has been saved to C:\\Users\\sIGORs\\.cache\\huggingface\\token\n",
      "Login successful.\n",
      "The current active token is: `jupyter-notebook`\n"
     ]
    }
   ],
   "source": "!huggingface-cli login --token <INSERT_TOKEN>"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a191ae8ad63576cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:29:23.753480Z",
     "start_time": "2025-04-22T15:29:20.662123Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\sIGORs\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n  * The NumPy version is: \"1.24.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\__init__.py:23\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m multiarray\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\multiarray.py:10\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mfunctools\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m overrides\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _multiarray_umath\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\overrides.py:7\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_inspect\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m getargspec\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_multiarray_umath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      8\u001B[39m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001B[32m     11\u001B[39m ARRAY_FUNCTIONS = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[31mImportError\u001B[39m: DLL load failed while importing _multiarray_umath: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\__init__.py:49\u001B[39m\n\u001B[32m     25\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msys\u001B[39;00m\n\u001B[32m     26\u001B[39m     msg = \u001B[33m\"\"\"\u001B[39m\n\u001B[32m     27\u001B[39m \n\u001B[32m     28\u001B[39m \u001B[33mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m     47\u001B[39m \u001B[33m\"\"\"\u001B[39m % (sys.version_info[\u001B[32m0\u001B[39m], sys.version_info[\u001B[32m1\u001B[39m], sys.executable,\n\u001B[32m     48\u001B[39m         __version__, exc)\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m envkey \u001B[38;5;129;01min\u001B[39;00m env_added:\n",
      "\u001B[31mImportError\u001B[39m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\sIGORs\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n  * The NumPy version is: \"1.24.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.auto.modeling_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1966\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1967\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m    125\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1206\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1178\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1149\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:690\u001B[39m, in \u001B[36m_load_unlocked\u001B[39m\u001B[34m(spec)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:940\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:241\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:30\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgeneration\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcandidate_generator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AssistantVocabTranslatorCache\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcache_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     33\u001B[39m     Cache,\n\u001B[32m     34\u001B[39m     DynamicCache,\n\u001B[32m   (...)\u001B[39m\u001B[32m     39\u001B[39m     StaticCache,\n\u001B[32m     40\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py:27\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_sklearn_available():\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m roc_curve\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcache_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DynamicCache\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py:84\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     81\u001B[39m     __check_build,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[32m     82\u001B[39m     _distributor_init,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[32m     83\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[32m     85\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_show_versions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m show_versions\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:19\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_metadata_requests\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester, _routing_enabled\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_bunch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Bunch\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_chunking\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gen_batches, gen_even_slices\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, validate_params\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mchunk_generator\u001B[39m(gen, chunksize):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m csr_matrix, issparse\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\__init__.py:295\u001B[39m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _spbase, sparray\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sparsetools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001B[32m     12\u001B[39m                            get_csr_submatrix)\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sputils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m upcast\n",
      "\u001B[31mImportError\u001B[39m: numpy._core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1966\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1967\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m    125\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1206\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1178\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1149\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:690\u001B[39m, in \u001B[36m_load_unlocked\u001B[39m\u001B[34m(spec)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:940\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:241\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:21\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mauto_factory\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     22\u001B[39m     _BaseAutoBackboneClass,\n\u001B[32m     23\u001B[39m     _BaseAutoModelClass,\n\u001B[32m     24\u001B[39m     _LazyAutoMapping,\n\u001B[32m     25\u001B[39m     auto_class_update,\n\u001B[32m     26\u001B[39m )\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfiguration_auto\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CONFIG_MAPPING_NAMES\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:40\u001B[39m\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgeneration\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GenerationMixin\n\u001B[32m     43\u001B[39m logger = logging.get_logger(\u001B[34m__name__\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1231\u001B[39m, in \u001B[36m_handle_fromlist\u001B[39m\u001B[34m(module, fromlist, import_, recursive)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1954\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._class_to_module.keys():\n\u001B[32m-> \u001B[39m\u001B[32m1955\u001B[39m     module = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1956\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1969\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1970\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m because of the following error (look up to see its\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1971\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1972\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy._core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m model_config = transformers.AutoConfig.from_pretrained(\n\u001B[32m      2\u001B[39m     pretrained_model_name_or_path=LLM_MODEL,\n\u001B[32m      3\u001B[39m )\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m model = \u001B[43mtransformers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mAutoModelForCausalLM\u001B[49m.from_pretrained(\n\u001B[32m      5\u001B[39m     pretrained_model_name_or_path=LLM_MODEL,\n\u001B[32m      6\u001B[39m     config=model_config,\n\u001B[32m      7\u001B[39m     quantization_config=bnb_config, \u001B[38;5;66;03m# we introduce the bnb config here.\u001B[39;00m\n\u001B[32m      8\u001B[39m     device_map=\u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m )\n\u001B[32m     10\u001B[39m model.eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1956\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1954\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._class_to_module.keys():\n\u001B[32m   1955\u001B[39m     module = \u001B[38;5;28mself\u001B[39m._get_module(\u001B[38;5;28mself\u001B[39m._class_to_module[name])\n\u001B[32m-> \u001B[39m\u001B[32m1956\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[32m   1957\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._modules:\n\u001B[32m   1958\u001B[39m     value = \u001B[38;5;28mself\u001B[39m._get_module(name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1953\u001B[39m     value = Placeholder\n\u001B[32m   1954\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._class_to_module.keys():\n\u001B[32m-> \u001B[39m\u001B[32m1955\u001B[39m     module = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1956\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[32m   1957\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._modules:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1967\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib.import_module(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m + module_name, \u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m)\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1969\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1970\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m because of the following error (look up to see its\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1971\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1972\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed to import transformers.models.auto.modeling_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy._core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    ")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config, # we introduce the bnb config here.\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370171a4b6a86e0d",
   "metadata": {},
   "source": [
    "We also need to load the tokenizer to transform the text as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085b8b5e7e48df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2711c6629b79e65",
   "metadata": {},
   "source": [
    "We will use pipelines from Hugging Face to perform the prompting and generation with the Mistral model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ebf83db21f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    #temperature=0.0,\n",
    "    max_new_tokens=8192,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90159704c59c8d37",
   "metadata": {},
   "source": [
    "We will use `langchain` to link the HuggingFace models and the chaining prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a9e634bead5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56feed9cfad5b",
   "metadata": {},
   "source": [
    "The core functionality of `langchain` is the creation of templates for prompting via `PromptTemplate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab547fad62f3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12aeac6f5a8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful AI QA assistant. When answering questions, use the context enclosed by triple backquotes if it is relevant.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Reply your answer in markdown format.\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ff19982849058",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ab9f78ce4d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ed18b29de3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844107785fc10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the scoring criteria of the NLP course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a12a13b3d7902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc132b9fa6e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What do I have to do for the peer review?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab746b668538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2d3ba58d14aaa",
   "metadata": {},
   "source": [
    "**NOTE**: The model provides responses that are fairly general. We plan to enhance this by integrating contextual details from our course materials via **RAG**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9240487369c8a24",
   "metadata": {},
   "source": [
    "### Enter RAG\n",
    "\n",
    "Next, we will define the vector embeddings of our context. We will use the `sentence-transformers/all-mpnet-base-v2` model to embed the documents and a FAISS vector store to store and later retrieve them. LangChain offers the `HuggingFaceEmbeddings` interface to easily load any model from Hugging Face to serve as the document representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f58f29d1a6c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd4731f85e8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a1d43e13aa57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_websites(sites: list[str]):\n",
    "    docs = []\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        filename = f\"{tmpdir}/site.html\"\n",
    "        for site in sites:\n",
    "            res = requests.get(site)\n",
    "            with open(filename, mode=\"wb\") as fp:\n",
    "                fp.write(res.content)\n",
    "            docs.extend(BSHTMLLoader(filename, open_encoding = 'utf8').load())\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf6c3f1ff8c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_webpage = \"https://docs.google.com/document/d/e/2PACX-1vRwReAm5Vz_aiNyZN33eTz22fqMJhM0H-KtJdXthUw5cean_WYdBkZgJchP_s9th0rtUW0ikZZ_Fh5l/pub\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f2abe19884a5f",
   "metadata": {},
   "source": [
    "The `fetch_websites` function will be used to scrape data from our Google Document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013f997c36d2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fetch_websites([course_webpage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd304f7d3f7c9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb6c70e3bac9f3",
   "metadata": {},
   "source": [
    "We loaded the entire course into a single document. Since the sentence transformer can handle only limited sections of text, this might be problematic. Next, we will use the `RecursiveCharacterTextSplitter` to split the document into chunks with a `chunk_size` of 1000 characters and a `chunk_overlap` of 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d0474faae5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2124183bcfebb",
   "metadata": {},
   "source": [
    "Let's see what the chunked document looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a78d50ca11f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfa7828d59a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd072c543c6634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b39987bd2a858",
   "metadata": {},
   "source": [
    "Next, we initialize a vector store. A vector store is a data structure that functions as a vector database, where each document is stored based on its own embedding. We will use the `FAISS` library for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4aef8084406765",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(all_splits, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639ebbad8683113",
   "metadata": {},
   "source": [
    "Finally, we define a retriever—an object that will handle the **retrieving** part of the RAG pipeline. The retriever receives as arguments the metric by which we search the space and the number of the k-nearest documents (chunks in our case) that we retrieve to present to the studen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e58a34f778c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44827c5c8dc5a5ab",
   "metadata": {},
   "source": [
    "Next, we modify our prompt template so that it now receives the context (the documents selected by the RAG system) and then generates the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6fe7081ceab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful AI QA assistant. When answering questions, use the context enclosed by triple backquotes if it is relevant.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Reply your answer in markdown format.\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=PROMPT_TEMPLATE.strip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aefe8951eaacc1",
   "metadata": {},
   "source": [
    "With the prompt defined, we next set up the `ConversationalRetrievalChain` that will utilize the defined `retriever` and `llm`, following the `PROMPT_TEMPLATE` to extract documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805381d21c53361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct complete LLM chain\n",
    "llm_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retreiver,\n",
    "    return_source_documents=False,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt_template},\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5229a0d7fcf4a",
   "metadata": {},
   "source": [
    "Finally, we create the `answer_question` function that will handle the chain invocation for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8390ab941f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history: dict[str] = None) -> str:\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    response = llm_chain.invoke({\"question\": question, \"chat_history\": history})\n",
    "    answer = response[\"answer\"].split(\"### Answer:\")[-1].strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd223d6a1c8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What do I have to do for the peer review?\"\n",
    "display_markdown(answer_question(question), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c6b213b988ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the first project about?\"\n",
    "display_markdown(answer_question(question), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b55adc68b293e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What do you have to do for a good grade?\"\n",
    "display_markdown(answer_question(question), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7e72b41ce6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the project intended for digital linguistics about?\"\n",
    "display_markdown(answer_question(question), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b275530b5888fe",
   "metadata": {},
   "source": [
    "With the introduction of RAG, the `Mistral` model was able to successfully answer questions about the NLP course.\n",
    "\n",
    "**Exercises:**\n",
    "* Implement a data loader script that can load documents from a folder.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04c4186181e74445835d74274dbebee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16793b1557dd42598acf5df018f029ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36042acd80ec4804a9396a69db64820c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcb6d7031f69424f922518e6203e1543",
      "placeholder": "​",
      "style": "IPY_MODEL_a01f72420fea410d9f3e66f4f436ee63",
      "value": " 3/3 [01:13&lt;00:00, 24.30s/it]"
     }
    },
    "62898c578fc54ca6996c1dc74be15ad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3df8004294c41eabbd8954a7b8ba8fd",
      "placeholder": "​",
      "style": "IPY_MODEL_dc41cc0f49374d27955be33ece1d4532",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "76dac92078e74b12a8d38527a8369acb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c204a58d85934023940648c4d736a7d6",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04c4186181e74445835d74274dbebee9",
      "value": 3
     }
    },
    "a01f72420fea410d9f3e66f4f436ee63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3df8004294c41eabbd8954a7b8ba8fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c204a58d85934023940648c4d736a7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc41cc0f49374d27955be33ece1d4532": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e33e7ceff6e942df9e6cea0270c0b2b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62898c578fc54ca6996c1dc74be15ad9",
       "IPY_MODEL_76dac92078e74b12a8d38527a8369acb",
       "IPY_MODEL_36042acd80ec4804a9396a69db64820c"
      ],
      "layout": "IPY_MODEL_16793b1557dd42598acf5df018f029ca"
     }
    },
    "fcb6d7031f69424f922518e6203e1543": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
